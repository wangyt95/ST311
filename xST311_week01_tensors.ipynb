{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlTk8fR7R0_I"
      },
      "source": [
        "Last review: Jan 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88PTlpIU72bH"
      },
      "source": [
        "# Basics of tensors\n",
        "\n",
        "This lab is based on material from Chapter 2 of [D2L (Classic version)](https://classic.d2l.ai/)\n",
        "\n",
        "- Data manipulation\n",
        "- Operations on tensors\n",
        "- Pandas: reading in data, handling missing values, converting variables to tensors\n",
        "- Automatic differentiation with `autograd` package\n",
        "\n",
        "## What is PyTorch?\n",
        "\n",
        "It’s a Python based scientific computing package targeted at two sets of audiences:\n",
        "\n",
        "-  Tensorial library that uses the power of GPUs\n",
        "-  A deep learning research platform that provides maximum flexibility and speed\n",
        "\n",
        "Import the PyTorch library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z_rCH7Ze72bI"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gETJGMaz72bJ"
      },
      "source": [
        "### Activity 1: Data manipulation\n",
        "\n",
        "Referring to Section 2.1.1, complete the following tasks:\n",
        "\n",
        "1.1(a) Using `arange` create a vector (1-dimensional tensor) of 6 evenly spaced values from 0 to 5. Name the vector x. Print x.\n",
        "Repeat but use `torch.tensor` instead of `arange`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrM322XQ72bK",
        "outputId": "26491a76-43e5-462c-f22e-efbad2d6a8f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5])\n",
            "tensor([0, 1, 2, 3, 4, 5])\n"
          ]
        }
      ],
      "source": [
        "#1a\n",
        "x = torch.arange(6)\n",
        "print(x)\n",
        "y = torch.tensor([0,1,2,3,4,5])\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWOb-mDQ72bL"
      },
      "source": [
        "To get help with a function use `?` (or do a web search) for example to see documentation for `torch.tensor`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UroLyuCj72bL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0;31mDocstring:\u001b[0m\n",
            "tensor(data, *, dtype=None, device=None, requires_grad=False, pin_memory=False) -> Tensor\n",
            "\n",
            "Constructs a tensor with no autograd history (also known as a \"leaf tensor\", see :doc:`/notes/autograd`) by copying :attr:`data`.\n",
            "\n",
            ".. warning::\n",
            "\n",
            "    When working with tensors prefer using :func:`torch.Tensor.clone`,\n",
            "    :func:`torch.Tensor.detach`, and :func:`torch.Tensor.requires_grad_` for\n",
            "    readability. Letting `t` be a tensor, ``torch.tensor(t)`` is equivalent to\n",
            "    ``t.clone().detach()``, and ``torch.tensor(t, requires_grad=True)``\n",
            "    is equivalent to ``t.clone().detach().requires_grad_(True)``.\n",
            "\n",
            ".. seealso::\n",
            "\n",
            "    :func:`torch.as_tensor` preserves autograd history and avoids copies where possible.\n",
            "    :func:`torch.from_numpy` creates a tensor that shares storage with a NumPy array.\n",
            "\n",
            "Args:\n",
            "    data (array_like): Initial data for the tensor. Can be a list, tuple,\n",
            "        NumPy ``ndarray``, scalar, and other types.\n",
            "\n",
            "Keyword args:\n",
            "    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
            "        Default: if ``None``, infers data type from :attr:`data`.\n",
            "    device (:class:`torch.device`, optional): the device of the constructed tensor. If None and data is a tensor\n",
            "        then the device of data is used. If None and data is not a tensor then\n",
            "        the result tensor is constructed on the current device.\n",
            "    requires_grad (bool, optional): If autograd should record operations on the\n",
            "        returned tensor. Default: ``False``.\n",
            "    pin_memory (bool, optional): If set, returned tensor would be allocated in\n",
            "        the pinned memory. Works only for CPU tensors. Default: ``False``.\n",
            "\n",
            "\n",
            "Example::\n",
            "\n",
            "    >>> torch.tensor([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]])\n",
            "    tensor([[ 0.1000,  1.2000],\n",
            "            [ 2.2000,  3.1000],\n",
            "            [ 4.9000,  5.2000]])\n",
            "\n",
            "    >>> torch.tensor([0, 1])  # Type inference on data\n",
            "    tensor([ 0,  1])\n",
            "\n",
            "    >>> torch.tensor([[0.11111, 0.222222, 0.3333333]],\n",
            "    ...              dtype=torch.float64,\n",
            "    ...              device=torch.device('cuda:0'))  # creates a double tensor on a CUDA device\n",
            "    tensor([[ 0.1111,  0.2222,  0.3333]], dtype=torch.float64, device='cuda:0')\n",
            "\n",
            "    >>> torch.tensor(3.14159)  # Create a zero-dimensional (scalar) tensor\n",
            "    tensor(3.1416)\n",
            "\n",
            "    >>> torch.tensor([])  # Create an empty tensor (of size (0,))\n",
            "    tensor([])\n",
            "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
          ]
        }
      ],
      "source": [
        "torch.tensor?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Nim7Dh88kGn"
      },
      "source": [
        "1.1(b) Using `arange` create tensor from -1.5 to 2.5 with each having a space of 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2elBMfj472bL",
        "outputId": "4d7d9d1d-538d-435f-f0bc-968fda61ace7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-1.5000, -1.0000, -0.5000,  0.0000,  0.5000,  1.0000,  1.5000,  2.0000,\n",
              "         2.5000,  3.0000])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You can use torch.tensor, but more efficient to do with with torch.arange\n",
        "torch.arange(-1.5, 3.0001, 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zOtuaqCS7UK"
      },
      "source": [
        "1.1(c) Refer to the documentation for [`torch.one_like()`](https://pytorch.org/docs/stable/generated/torch.ones_like.html) to understand the following output of the code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jide0WcXS0y7",
        "outputId": "7214c8dc-3f1c-4044-ac2a-04df8857e0e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 1])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(x)\n",
        "torch.ones_like(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuyABpLu72bL"
      },
      "source": [
        "1.2(a) Apply the function `len` and `shape` to x. What do these output?(And how is this related to the dimension of the vector x? (see page 55))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQK8IdZ_72bM",
        "outputId": "64f467ea-e676-41a3-f4e7-54e3624c682a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Lenth: 6\n",
            "Shape: torch.Size([6])\n"
          ]
        }
      ],
      "source": [
        "#2a\n",
        "print(f\" Lenth: {len(x)}\") # returns number of elements\n",
        "\n",
        "# shape is an attribute of a tensor.\n",
        "print(f\"Shape: {x.shape}\") # length along each axis (only 1 axis)\n",
        "\n",
        "#Common error made by students: shape(x)\n",
        "# shape is part of numpy, so you need to\n",
        "# import numpy as np\n",
        "# Then\n",
        "# np.shape(x)\n",
        "\n",
        "# (p.55) Note that the word “dimension” tends to get overloaded in these contexts and this tends to confuse\n",
        "# people. To clarify, we use the **dimensionality of a vector or an axis** to refer to its length, i.e., the\n",
        "# number of elements of a vector or an axis. However, we use the **dimensionality of a tensor** to refer\n",
        "# to the number of axes that a tensor has."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlrqQrpv72bM"
      },
      "source": [
        "1.2(b) What's the difference between `torch.tensor(2)` and `torch.tensor([2])`. Look at their shapes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd5EzxhT72bM",
        "outputId": "8f6ad856-5fd7-405d-fa18-dfaa701a1f4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([])\n",
            "torch.Size([1])\n",
            "torch.Size([1, 1])\n",
            "torch.Size([1, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "print(torch.tensor(2).shape) # this is rank 0 tensor. It is a scalar\n",
        "print(torch.tensor([2]).shape) # 1d tensor\n",
        "print(torch.tensor([[2]]).shape)\n",
        "print(torch.tensor([[[2]]]).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "up5oU42IuTFZ"
      },
      "source": [
        "`torch.flatten()` can reduce the dimensionality of a tensor if in some place it has dimension 1.\n",
        "It also works for scalers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGaBZtHQuTFZ",
        "outputId": "2a90e7bd-1797-42c5-fc05-2c37c1e1b65e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1])\n",
            "torch.Size([1])\n",
            "torch.Size([1])\n",
            "tensor(2)\n",
            "torch.Size([1, 1, 1, 1, 1])\n",
            "torch.Size([1])\n"
          ]
        }
      ],
      "source": [
        "test_x = torch.tensor([[2]])\n",
        "print(test_x.shape)\n",
        "test_y = torch.flatten(test_x)\n",
        "print(test_y.shape)\n",
        "\n",
        "test_scaler = torch.tensor(2)\n",
        "print(torch.flatten(test_scaler).shape)\n",
        "print(test_scaler)\n",
        "\n",
        "test_xx = torch.tensor([[[[[2]]]]])\n",
        "print(test_xx.shape)\n",
        "print(torch.flatten(test_xx).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWEn_1u472bN"
      },
      "source": [
        "1.2(c) Study the code below. What is the purpose of `dtype=torch.float32`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMw7RaScADU_",
        "outputId": "d852a838-43d6-489d-ede2-3ecbcad42017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5])\n",
            "tensor([0., 1., 2., 3., 4., 5.])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([True, True, True, True, True, True])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.arange(6)\n",
        "x2 = torch.arange(6, dtype=torch.float32)\n",
        "print(x)\n",
        "print(x2)\n",
        "x == x2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQcNi2li72bN"
      },
      "source": [
        "1.3(a) Use the `reshape` function to change the shape of the tensor x from a row vector to a matrix (2d tensor) with shape 2 rows and 3 columns, .i.e shape (2,3). Call it X. Print X. How many axes are there?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iumlrrzE72bN",
        "outputId": "c6470c75-4657-4307-8936-fc6c6b1d500a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n"
          ]
        }
      ],
      "source": [
        "#3a\n",
        "X = x.reshape(2,3)\n",
        "print(X)\n",
        "## axes=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3wpjlngN3-C",
        "outputId": "3a88e93b-b1b4-423a-942e-bb983a973b96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5])\n",
            "tensor([0, 1, 2, 3, 4, 5])\n"
          ]
        }
      ],
      "source": [
        "print(x)\n",
        "\n",
        "x.reshape(2,3)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v2Uv5hL72bN"
      },
      "source": [
        "1.3(b) Look up `torch.view` to understand the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF_rd_dE72bN",
        "outputId": "720cb851-052f-4dfa-e520-64605031d5ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5]])\n",
            "tensor([0, 1, 2, 3, 4, 5])\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n"
          ]
        }
      ],
      "source": [
        "print(x.view(2,3).view(-1,2))\n",
        "\n",
        "xxx = x.view(2,3)\n",
        "#torch.view comes in very handy as we do\n",
        "# not need to keep track of the size of 2 axes.\n",
        "# just give it one, and set the other to -1 and it will\n",
        "# figure it out.\n",
        "\n",
        "print(x)\n",
        "print(xxx)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6nGZe_0OS2H",
        "outputId": "cafcd4ed-9f11-415f-c3b0-983c9500426e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1,  2,  3],\n",
              "         [ 4,  5,  6,  7],\n",
              "         [ 8,  9, 10, 11]],\n",
              "\n",
              "        [[12, 13, 14, 15],\n",
              "         [16, 17, 18, 19],\n",
              "         [20, 21, 22, 23]]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_x = torch.arange(24)\n",
        "test_x.reshape(2,-1,4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyjMk6QI72bN"
      },
      "source": [
        "1.4 How is the `-1` used in the reshape function? Repeat question 3a but using `-1` as one of the arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRKeInLU72bO",
        "outputId": "1095acc0-6d4a-4bd6-a948-b621d1226163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n"
          ]
        }
      ],
      "source": [
        "#4\n",
        "X=x.reshape(-1,3) # -1 may apear in either of the two arguments\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjcYH85K72bO"
      },
      "source": [
        "1.5 (Relating to Question 4) Without running code what will be the ouput of `x.reshape(-1,-1)`?  And for  `x.reshape(-1,4)`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TeLTwHPe72bO"
      },
      "outputs": [],
      "source": [
        "#5\n",
        "# x.reshape(-1,-1) need to know at least one of the number of rows, columns to figure out the other.\n",
        "# x.reshape(-1,,4) returns error as shape does not match size of 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgB9panzPOtx"
      },
      "source": [
        "At this point you may be thinking that `view` and `reshape` are the same thing. Well there is a subtle difference, which you can read about on [Stackoverflow](https://stackoverflow.com/questions/49643225/whats-the-difference-between-reshape-and-view-in-pytorch), but doesn't matter for us. In DL you will see `view` is more commonly used.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUuloZxi72bO"
      },
      "source": [
        "1.6 First, create a tensor with shape (3,5) whose elements are sampled from a standard normal distribution. Verify that when you run the same code you should get different numbers. Next, use `torch.manual_seed()` to get identical random draws to the tensor you created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvEamzpj72bO",
        "outputId": "732dc885-84d7-4496-a589-46b328fe968e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.0302, -0.5073, -0.1017,  1.3587, -3.0745],\n",
              "        [-0.7659,  0.7240,  0.2416, -1.5601,  1.3164],\n",
              "        [-0.8576, -0.3336, -2.5873, -0.1829, -0.4056]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(22)\n",
        "torch.randn(3,5)\n",
        "\n",
        "# why set the seed?\n",
        "# Only makes a difference if our procedures involve\n",
        "# random sampling, such as sampling from some statistical distribution.\n",
        "# Setting the seed allows others to reproduce your results - which you\n",
        "# may have reported in a published paper. Reproducibility is important."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjC9hYqZ72bO"
      },
      "source": [
        "### Activity 2: Operations on tensors\n",
        "\n",
        "\n",
        "2.1.(Section 2.1.2) Create the following 2x5 matrices whose:\n",
        "\n",
        "- values are integers from 0 to 9. Use `arange`, and have as one of the arguments `-1` in `reshape`. Call the matrix A.\n",
        "\n",
        "- values are drawn from a standard normal distribution and call it B\n",
        "\n",
        "- elements are zero and call it C\n",
        "\n",
        "- elements are ones and call it D\n",
        "\n",
        "a. raise each element of A to the power 2.\n",
        "\n",
        "b. Concatenate D on top of C on axis=0 get a $4\\times 5$ matrix and print the result.\n",
        "\n",
        "c. Concatenate D and C on axis 1 to get a $2\\times 10$ matrix and print the result.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKPbeBWw72bP",
        "outputId": "1a175758-1480-4234-d6da-c403d724bdce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.,  1.,  4.,  9., 16.],\n",
            "        [25., 36., 49., 64., 81.]])\n",
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#1.\n",
        "A=torch.arange(10, dtype=torch.float32).reshape(-1,5)\n",
        "B=torch.randn(2,5,dtype=torch.float32)\n",
        "C=torch.zeros(2,5,dtype=torch.float32)\n",
        "D=torch.ones((2,5))\n",
        "\n",
        "A**2 # element-wise operation\n",
        "print(A**2)\n",
        "print(torch.cat((D,C),axis=0))\n",
        "torch.cat((D,C),axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H48Sd1gH72bP"
      },
      "source": [
        "2.2(a) (Section 2.1.3) Add a scalar,say 10, to matrix A. Print the result, and explain what operation has been performed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV3R-xfP72bP",
        "outputId": "6f623930-7d64-4a74-ba87-2e262e732a40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 1., 2., 3., 4.],\n",
            "        [5., 6., 7., 8., 9.]])\n",
            "tensor([[10., 11., 12., 13., 14.],\n",
            "        [15., 16., 17., 18., 19.]])\n",
            "tensor([[10., 11., 12., 13., 14.],\n",
            "        [15., 16., 17., 18., 19.]])\n"
          ]
        }
      ],
      "source": [
        "#2a\n",
        "#Broadcasting mechanism is applied\n",
        "# Note, not all function support broadcasting - torch.mm does not for example.\n",
        "print(A)\n",
        "print(A+10)\n",
        "\n",
        "print(A + 10 * torch.ones_like(A))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2Xbwy-f72bP"
      },
      "source": [
        "2.2(b) Add a vector `b=(6,0,2,-3.2,5)` to matrix A. Before writing the code, what do you expect will be the output? Verify it.\n",
        "In the output, why are there a bunch of zeros after the decimal place?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgSseS2z72bP",
        "outputId": "48d48664-7c43-4f84-f4d4-d810072994a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 6.0000,  1.0000,  4.0000, -0.2000,  9.0000],\n",
              "        [11.0000,  6.0000,  9.0000,  4.8000, 14.0000]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b=torch.tensor([6,0,2,-3.2,5])\n",
        "A+b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5QJFaCuRCA9",
        "outputId": "e8d66c16-ef82-44bf-d217-835072115a16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
            "        [25., 26., 27., 28., 29.]])\n"
          ]
        }
      ],
      "source": [
        "c = torch.tensor([[1], [20]])\n",
        "c\n",
        "\n",
        "print(A+c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWT4Dc9t72bQ"
      },
      "source": [
        "2.2(c) (This question is a useful reference for softmax regression.) What does `argmax(axis=1)` and `max` do when applied to the matrix `A`? See the following application of the two functions.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Upa5MMak72bQ",
        "outputId": "7ac60397-c161-4227-a122-60a476b2e174"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 1., 2., 3., 4.],\n",
            "        [5., 6., 7., 8., 9.]])\n",
            "tensor([4, 4])\n",
            "tensor(9.)\n"
          ]
        }
      ],
      "source": [
        "print(A)\n",
        "print(A.argmax(axis=1)) # in each row, which is the max\n",
        "print(A.max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoEOGuJE72bQ"
      },
      "source": [
        "Solution to 2c. `argmax(axis=1)` returns the index corresponding to the largest value per row; `max` returns the largest value in the matrix `A`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11fEW6cc72bQ"
      },
      "source": [
        "2.2(d) The following code returns and error. Correct it. (Hint: see Activity 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJqdXwNe72bQ",
        "outputId": "7d723b40-8312-4971-8ca4-3336fba93786"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(45.)\n",
            "tensor(4.5000)\n"
          ]
        }
      ],
      "source": [
        "print(A.sum())\n",
        "print(A.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NclF_mEj72bQ"
      },
      "source": [
        "2.2(e) (This question is a useful reference for convoluational neural nets.) The following code multiplies matrices F and G. Without running the code, what are the outputs?\n",
        "run the code to verify your answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GTlQxip72bQ",
        "outputId": "b71826f4-7c82-4b8e-c004-f046e4610c00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[2, 3],\n",
            "        [5, 7]])\n",
            "tensor([[17, 17],\n",
            "        [17, 17]])\n",
            "tensor(17)\n",
            "l is tensor([[ 1,  4],\n",
            "        [16, 36]])\n",
            "tensor(57)\n"
          ]
        }
      ],
      "source": [
        "F=torch.tensor([[1,1],[1,1]])\n",
        "G=torch.tensor([[2,3],[5,7]])\n",
        "\n",
        "#What are the outputs to:\n",
        "print(F*G)\n",
        "print(F*G.sum()) # equivalent to print(F* ( G.sum() ) )\n",
        "print((F*G).sum())\n",
        "\n",
        "l = (F-G)**2\n",
        "print(f'l is {l}')\n",
        "print(l.sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50iEGLTA72bR"
      },
      "source": [
        "2.3 (Section 2.1.4)\n",
        "\n",
        "a. Write code to obtain the following element(s) of matrix A:\n",
        "\n",
        "- First row\n",
        "\n",
        "- Last row\n",
        "\n",
        "- row 2 column 2 element\n",
        "\n",
        "- third column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3gaVRBL72bR",
        "outputId": "8d7c2f18-bded-4ffd-f7c8-3cb3144ac9fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 1., 2., 3., 4.],\n",
            "        [5., 6., 7., 8., 9.]])\n",
            "\n",
            "1st row is tensor([0., 1., 2., 3., 4.]) \n",
            "\n",
            "last row is tensor([5., 6., 7., 8., 9.]) \n",
            "\n",
            "(2,2) element is 6.0\n",
            "\n",
            "3rd column is tensor([2., 7.])\n"
          ]
        }
      ],
      "source": [
        "print(A)\n",
        "print(f\"\\n1st row is {A[0]} \\n\")\n",
        "print(f\"last row is {A[-1]} \\n\")\n",
        "print(f\"(2,2) element is {A[1,1]}\\n\")\n",
        "print(f\"3rd column is {A[:,2]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk16jwqR72bR"
      },
      "source": [
        "b. (3d tensor) Create a tensor with integers from 0 to 7 where there are 2 blocks of 2x2 matrices. Use `arange` and `reshape`. Call it E.\n",
        "\n",
        "- How many axes does this tensor have?\n",
        "\n",
        "- Display the 2nd element which is a matrix\n",
        "\n",
        "- Without using code, what will be returned by the code E[0,1,0]? Verify by running the code.\n",
        "\n",
        "- Write the code that will output from E the tensor [4,5]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4PPG6Y872bR",
        "outputId": "d22fd7d1-a745-4249-ea71-ed43a4366563"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[0, 1],\n",
            "         [2, 3]],\n",
            "\n",
            "        [[4, 5],\n",
            "         [6, 7]]])\n",
            "torch.Size([2, 2, 2])\n",
            "Output [4,5] is obtained by running E[1,0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[4, 5],\n",
              "        [6, 7]])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "E = torch.arange(8).reshape((2,2,-1))\n",
        "print(E)\n",
        "print(E.shape) # Number of axes = 3\n",
        "E[0,1,0]\n",
        "print(f\"Output [4,5] is obtained by running E[1,0]\")\n",
        "E[0,:,:]\n",
        "\n",
        "E[1,:,:]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6uUxJlu72bR"
      },
      "source": [
        "2.4 (Section 2.3.6 p59)\n",
        "\n",
        "a0. Use `sum` to find the sum of the elements of the tensor x in Activity 1. (How is `sum(x)` different to `x.sum()`?)\n",
        "\n",
        "a. Sum across the rows of matrix A. What is the size of the resulting tensor?\n",
        "\n",
        "b. Sum across all elements of A. What is the size of the resulting tensor? Do this two ways: using `torch.sum` (not in book), and `sum`.\n",
        "\n",
        "c. Compute the mean of all the elements A. (The dtype must be floating point. If you didn't do so already, add `dtype=torch.float32` when you created A.)\n",
        "\n",
        "d. (Reduction and non-reduction sum). Compute the mean of the first row of A in such a way that one axis is lost, and then in a way where you keep all the axes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcvoWRYV72bR",
        "outputId": "7fe7f609-68cd-4d4b-979d-14e3978c8f6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sum of x is 15\n",
            "tensor([[0., 1., 2., 3., 4.],\n",
            "        [5., 6., 7., 8., 9.]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 1])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#a0\n",
        "print(f\"sum of x is {x.sum()}\")\n",
        "# x.sum() works on a tensor.\n",
        "\n",
        "#a\n",
        "print(A)\n",
        "#A.sum(dim=1)\n",
        "#A.sum(1).shape  #size = nrows = 2\n",
        "\n",
        "#b\n",
        "torch.sum(A)\n",
        "A.sum(axis=[0,1])\n",
        "\n",
        "#c\n",
        "A=torch.arange(10,).reshape(-1,5)\n",
        "#A.mean() # error as dtype not floating point\n",
        "A=torch.arange(10, dtype=torch.float32).reshape(-1,5)\n",
        "A.mean()\n",
        "\n",
        "#d\n",
        "A.mean(axis=1)\n",
        "A.mean(axis=1).shape  #1 axis\n",
        "A.mean(axis=1,keepdims=True)\n",
        "A.mean(axis=1,keepdims=True).shape #2 axes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITK7kq7j72bS"
      },
      "source": [
        "2.5 Suppose you have a model that has generated predictions `yhat=torch.tensor([2,2,2])`.The observations are `y=torch.tensor([1,6,2])`. Write code that outputs the residual sum of squares (RSS) given by\n",
        "\n",
        "$$\n",
        "\\text{RSS} = \\sum_{i=1}^n(y_i-\\hat{y}_i)^2\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "5dRPkRoI72bS",
        "outputId": "17795c87-65ff-4f75-fb56-c4ada801879f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(17)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#2.5\n",
        "y = torch.tensor([1,6,2])\n",
        "yhat = torch.tensor([2,2,2])\n",
        "l = (y-yhat)**2  #vector of squared difference for each observation\n",
        "l.sum()   #RSS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5LcqUFY72bS"
      },
      "source": [
        "If you have time, look at the following in class, otherwise do it in your own time.\n",
        "\n",
        "2.6 There are a number of different ways to multiply in linear algebra. Work through (by trying similar examples from the book) Section 2.3.7 (dot products), 2.3.8(Matrix-vector products),2.3.9 (Matrix-matrix multiplication)\n",
        "\n",
        "2.7 Section 2.4 calculus. Just need to know the math from this.\n",
        "\n",
        "2.8 Study the following tensor operations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IoI1gjE72bS",
        "outputId": "fcb37735-b110-4d9c-e02f-9c1afedbe97a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n",
            "tensor([[-1.0399,  0.5931, -0.0092,  0.4597, -0.5789],\n",
            "        [-0.6114,  1.0012, -0.3074, -0.0964,  0.8330]])\n",
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n",
            "tensor([[-1.1162, -1.7039, -0.7843,  0.3339, -0.7833],\n",
            "        [-1.1815,  0.2252, -0.6599,  0.7028, -1.0351]])\n",
            "tensor([[-1.2325, -2.4079, -0.5686,  1.6678, -0.5667],\n",
            "        [-1.3629,  1.4503, -0.3198,  2.4056, -1.0703]])\n",
            "tensor([[-1.1162, -1.7039, -0.7843,  0.3339, -0.7833],\n",
            "        [-1.1815,  0.2252, -0.6599,  0.7028, -1.0351]])\n"
          ]
        }
      ],
      "source": [
        "#Q8: Tensor operations\n",
        "C = torch.zeros(2,5,dtype=torch.float32)\n",
        "print(C)\n",
        "print(C.new_empty(C.size()).normal_()) # does not affect the memory of C\n",
        "print(C)\n",
        "C1 = C.new_empty(C.size()).normal_()\n",
        "print(C1)\n",
        "print(C1.mul(2).add(1))\n",
        "C1.mul(2).add(1)\n",
        "print(C1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81WDAEJauTFb"
      },
      "source": [
        "It is important to understand what operations are done in-place."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-RjIfNz72bT"
      },
      "source": [
        "### Activity 3 - Pandas\n",
        "\n",
        "Review Section 2.2.1-2.2.3\n",
        "\n",
        "-  (2.2.1) reading in data in csv format\n",
        "-  (2.2.2) handling missing data by imputation\n",
        "-  (2.2.3) conversion variables in panda to tensors\n",
        "\n",
        "3.1 Create a 1d tensor `tensor([2, 3, 4])` using `arange`. Use `type` which we expect to be a tensor.\n",
        "Convert it to a numpy array. For this you need to first `import numpy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dZed9yE172bT",
        "outputId": "434a07ec-6a07-495b-8fd2-2c5099ef4802"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2, 3, 4])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.arange(2,5)\n",
        "print(a)\n",
        "type(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "_z7y3InH72bT"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "50d2_0sn72bT",
        "outputId": "0686d930-d0a8-436b-f398-01e8b4d61691"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a_np = a.numpy()\n",
        "type(a_np)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ekzh95z72bT"
      },
      "source": [
        "## 2.5 Automatic differentiation\n",
        "\n",
        "This section contains the idea behind how we train neural nets.\n",
        "We will see the details in Lecture 2. This section gives you a simple demo.\n",
        "\n",
        "The [`autograd` package](http://pytorch.org/docs/autograd) provides automatic differentiation of **scalar valued functions**. We use it to specify learnable parameters of a model for PyTorch's optimizers to update. This set-up is exactly what we want for deep learning.\n",
        "\n",
        "The learnable parameters must be of floating point tensor types (or complex tensor type, but this isn't relevant for this course).\n",
        "\n",
        "Demo\n",
        "\n",
        "1. First create the inputs $x$ and $y$ with values at which we wish to know the derivative, and attach gradients to those variables with respect to which we want partial derivative. We can do this by adding `requires_grad=True` to torch tensors.\n",
        "2. Create the function. In this course our objective function - the loss function - is a scalar function (i.e. output is a scalar), so we will consider only scalar functions.\n",
        "3. Obtain the derivatives by running the function for backpropagation.\n",
        "\n",
        "You can then access the gradient, for example by printing it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEywlKwQ72bT",
        "outputId": "0e80d8c4-e725-4d77-c66d-c2e9cd546cb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2., 0.], requires_grad=True)\n",
            "tensor([0., 3.], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "#1\n",
        "x = torch.tensor([2.,0],requires_grad=True)\n",
        "y = torch.tensor([0.,3.],requires_grad=True)\n",
        "print(x)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehUOCNc272bT",
        "outputId": "d605edaa-7858-4b92-a74f-c7322c1a2a33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 4., 27.], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "#2\n",
        "# Here I am creating a function s = x1^2+x2^2+y1^3+y2^3\n",
        "# The question: what is the partial derivative of s w.r.t the parameters\n",
        "# which are : x1,x2,y1,y2 computed at x1=2,x2=0,y1=0,y2=3?\n",
        "# This is answered by automatic differentiation algorithm backward().\n",
        "\n",
        "z = x**2 + y**3\n",
        "s = z.sum()\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xB1GzX5L72bU"
      },
      "source": [
        "`z` and `s` were created as a result of an operation on tensors, so has a`grad_fn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPywrdwt72bU",
        "outputId": "f08e49d7-86f6-4ed2-8181-44d6260d1d06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<AddBackward0 object at 0x11f05a8e0>\n",
            "<SumBackward0 object at 0x1075fafd0>\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "#Each variable has a .grad_fn attribute that references a function that has\n",
        "#created a function (except for Tensors created by the user - these have None as .grad_fn).\n",
        "print(z.grad_fn)\n",
        "print(s.grad_fn)\n",
        "print(x.grad_fn)\n",
        "print(x.grad)\n",
        "print(y.grad_fn)\n",
        "print(y.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86B5rF9u72bU",
        "outputId": "ef84d4d3-459c-4dd7-e192-93e5977c90c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "tensor([4., 0.])\n",
            "tensor([ 0., 27.])\n"
          ]
        }
      ],
      "source": [
        "#3\n",
        "#Reset gradients if re-running step 2 (the forward pass)\n",
        "#y.grad.zero_()\n",
        "#x.grad.zero_()\n",
        "\n",
        "s.backward() #obtains derivatives w.r.t. the learnable parameters x,y\n",
        "\n",
        "print(x.grad_fn)\n",
        "print(x.grad) #contains the partial derivatives of s w.r.t x computed at values of x\n",
        "print(y.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKGsl2NrE_uO"
      },
      "source": [
        "The codes in step 1-3 defines a **computational graph**. `Autograd` supports automatic computation of gradient for any computational graph.\n",
        "\n",
        "We can view the PyTorch graph using `torchviz` package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "cp_Tgzh_72bU"
      },
      "outputs": [],
      "source": [
        "# Need to install torchviz if using either Jupyter or Colab\n",
        "# !pip install torchviz\n",
        "from torchviz import make_dot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "U7UdGoxsEfI3",
        "outputId": "b05c6373-0ff7-4a9b-c6a1-af7df897e704"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": [
              "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
              "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
              " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
              "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
              " -->\n",
              "<!-- Pages: 1 -->\n",
              "<svg width=\"226pt\" height=\"337pt\"\n",
              " viewBox=\"0.00 0.00 226.00 336.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
              "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 332.5)\">\n",
              "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-332.5 222,-332.5 222,4 -4,4\"/>\n",
              "<!-- 4815522848 -->\n",
              "<g id=\"node1\" class=\"node\">\n",
              "<title>4815522848</title>\n",
              "<polygon fill=\"#caff70\" stroke=\"black\" points=\"136,-32.75 82,-32.75 82,0 136,0 136,-32.75\"/>\n",
              "<text text-anchor=\"middle\" x=\"109\" y=\"-7.25\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
              "</g>\n",
              "<!-- 4820969648 -->\n",
              "<g id=\"node2\" class=\"node\">\n",
              "<title>4820969648</title>\n",
              "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"153,-89.5 65,-89.5 65,-68.75 153,-68.75 153,-89.5\"/>\n",
              "<text text-anchor=\"middle\" x=\"109\" y=\"-76\" font-family=\"monospace\" font-size=\"10.00\">SumBackward0</text>\n",
              "</g>\n",
              "<!-- 4820969648&#45;&gt;4815522848 -->\n",
              "<g id=\"edge8\" class=\"edge\">\n",
              "<title>4820969648&#45;&gt;4815522848</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M109,-68.36C109,-61.89 109,-53.05 109,-44.55\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"112.5,-44.55 109,-34.55 105.5,-44.55 112.5,-44.55\"/>\n",
              "</g>\n",
              "<!-- 4820969744 -->\n",
              "<g id=\"node3\" class=\"node\">\n",
              "<title>4820969744</title>\n",
              "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"153,-146.25 65,-146.25 65,-125.5 153,-125.5 153,-146.25\"/>\n",
              "<text text-anchor=\"middle\" x=\"109\" y=\"-132.75\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
              "</g>\n",
              "<!-- 4820969744&#45;&gt;4820969648 -->\n",
              "<g id=\"edge1\" class=\"edge\">\n",
              "<title>4820969744&#45;&gt;4820969648</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M109,-125.09C109,-118.47 109,-109.47 109,-101.27\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"112.5,-101.34 109,-91.34 105.5,-101.34 112.5,-101.34\"/>\n",
              "</g>\n",
              "<!-- 4820969552 -->\n",
              "<g id=\"node4\" class=\"node\">\n",
              "<title>4820969552</title>\n",
              "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"100,-203 12,-203 12,-182.25 100,-182.25 100,-203\"/>\n",
              "<text text-anchor=\"middle\" x=\"56\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n",
              "</g>\n",
              "<!-- 4820969552&#45;&gt;4820969744 -->\n",
              "<g id=\"edge2\" class=\"edge\">\n",
              "<title>4820969552&#45;&gt;4820969744</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M65.48,-181.84C72.79,-174.28 83.09,-163.64 91.84,-154.6\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"94.11,-157.29 98.55,-147.67 89.08,-152.42 94.11,-157.29\"/>\n",
              "</g>\n",
              "<!-- 4820969840 -->\n",
              "<g id=\"node5\" class=\"node\">\n",
              "<title>4820969840</title>\n",
              "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"100,-259.75 0,-259.75 0,-239 100,-239 100,-259.75\"/>\n",
              "<text text-anchor=\"middle\" x=\"50\" y=\"-246.25\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
              "</g>\n",
              "<!-- 4820969840&#45;&gt;4820969552 -->\n",
              "<g id=\"edge3\" class=\"edge\">\n",
              "<title>4820969840&#45;&gt;4820969552</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M51.07,-238.59C51.8,-231.97 52.78,-222.97 53.68,-214.77\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"57.16,-215.15 54.77,-204.83 50.2,-214.39 57.16,-215.15\"/>\n",
              "</g>\n",
              "<!-- 4420352176 -->\n",
              "<g id=\"node6\" class=\"node\">\n",
              "<title>4420352176</title>\n",
              "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77,-328.5 23,-328.5 23,-295.75 77,-295.75 77,-328.5\"/>\n",
              "<text text-anchor=\"middle\" x=\"50\" y=\"-303\" font-family=\"monospace\" font-size=\"10.00\"> (2)</text>\n",
              "</g>\n",
              "<!-- 4420352176&#45;&gt;4820969840 -->\n",
              "<g id=\"edge4\" class=\"edge\">\n",
              "<title>4420352176&#45;&gt;4820969840</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M50,-295.48C50,-288.1 50,-279.18 50,-271.24\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-271.41 50,-261.41 46.5,-271.41 53.5,-271.41\"/>\n",
              "</g>\n",
              "<!-- 4820969408 -->\n",
              "<g id=\"node7\" class=\"node\">\n",
              "<title>4820969408</title>\n",
              "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"209,-203 121,-203 121,-182.25 209,-182.25 209,-203\"/>\n",
              "<text text-anchor=\"middle\" x=\"165\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n",
              "</g>\n",
              "<!-- 4820969408&#45;&gt;4820969744 -->\n",
              "<g id=\"edge5\" class=\"edge\">\n",
              "<title>4820969408&#45;&gt;4820969744</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M154.99,-181.84C147.26,-174.28 136.37,-163.64 127.13,-154.6\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"129.6,-152.12 120.01,-147.64 124.71,-157.13 129.6,-152.12\"/>\n",
              "</g>\n",
              "<!-- 4820969888 -->\n",
              "<g id=\"node8\" class=\"node\">\n",
              "<title>4820969888</title>\n",
              "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"218,-259.75 118,-259.75 118,-239 218,-239 218,-259.75\"/>\n",
              "<text text-anchor=\"middle\" x=\"168\" y=\"-246.25\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
              "</g>\n",
              "<!-- 4820969888&#45;&gt;4820969408 -->\n",
              "<g id=\"edge6\" class=\"edge\">\n",
              "<title>4820969888&#45;&gt;4820969408</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M167.46,-238.59C167.1,-231.97 166.61,-222.97 166.16,-214.77\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"169.66,-214.63 165.61,-204.84 162.67,-215.02 169.66,-214.63\"/>\n",
              "</g>\n",
              "<!-- 4815682112 -->\n",
              "<g id=\"node9\" class=\"node\">\n",
              "<title>4815682112</title>\n",
              "<polygon fill=\"lightblue\" stroke=\"black\" points=\"195,-328.5 141,-328.5 141,-295.75 195,-295.75 195,-328.5\"/>\n",
              "<text text-anchor=\"middle\" x=\"168\" y=\"-303\" font-family=\"monospace\" font-size=\"10.00\"> (2)</text>\n",
              "</g>\n",
              "<!-- 4815682112&#45;&gt;4820969888 -->\n",
              "<g id=\"edge7\" class=\"edge\">\n",
              "<title>4815682112&#45;&gt;4820969888</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M168,-295.48C168,-288.1 168,-279.18 168,-271.24\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"171.5,-271.41 168,-261.41 164.5,-271.41 171.5,-271.41\"/>\n",
              "</g>\n",
              "</g>\n",
              "</svg>\n"
            ],
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x11f5a2820>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "make_dot(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgbDY69L72bV"
      },
      "source": [
        "\n",
        "### Activity 4\n",
        "\n",
        "1.In the above example:\n",
        "\n",
        "a. What happens to the derivatives w.r.t inputs if we remove `requires_grad=True` from $y$?\n",
        "\n",
        "b. After running the code through once, run again steps 2 and 3? Explain the values you see for the gradients.\n",
        "Look in Section 2.5.1 to see what we should add in step 2 to reset the gradients.\n",
        "\n",
        "\n",
        "2.What is the derivative of $y = 2\\mathbf{x}^{\\top}\\mathbf{x}$ with respect to the column vector $\\mathbf{x}$?\n",
        "Now study and repeat the toy example in Section 2.5.1. relating to computing the derivative for this function.\n",
        "\n",
        "3.Work through the notebooks accompanying the text for Section 2.5.2.(Backward for non-scalar variables), and Section 2.5.3. (Detaching computation).\n",
        "(We will use detach when we in the gradient descent algorithm.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FwD9soc72bV"
      },
      "outputs": [],
      "source": [
        "# 1a. y becomes a constant, so there is no derivative w.r.t y. If you remove all learnable parameters, the graph\n",
        "# does not track the history of the computation of the parameters.\n",
        "# b. The values of the gradients are wrong. When rerun the previous results are accumulated.\n",
        "# Reset gradients with <object>.grad.zero_() before calling .backward()\n",
        "\n",
        "# 2. the derivative w.r.t vector x is 4x. (See Section 2.4.3 p70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "172vD2tf72bV"
      },
      "source": [
        "### Activity 5\n",
        "\n",
        "The aim is understand the function in Section 2.5.4 and serves as a review of loops.\n",
        "\n",
        "The code below is a simplified version of the function in Section 2.5.4\n",
        "\n",
        "1.Without running the code, what is the output that will be displayed? Verify by running the program.\n",
        "If you can't figure out what the code is doing, use Python Tutor to break down the steps. (Paste the code into [Python Tutor](https://pythontutor.com/python-debugger.html#mode=edit)).\n",
        "\n",
        "2.Now analyse the program in Section 2.5.4. (The documentation for `norm` recommends replacing it by `torch.linalg.vector_norm`. Does it matter to replace `b.sum()` by `b`?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKxutgRC72bV",
        "outputId": "d3ccb00c-8e0a-4d2d-904a-23ff0fcff57b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-40.0\n"
          ]
        }
      ],
      "source": [
        "def f(a):\n",
        "    b = a * 2\n",
        "    while abs(b) < 4:\n",
        "        b = b * 2\n",
        "    if b > 0:\n",
        "        c = b\n",
        "    else:\n",
        "        c = 10 * b\n",
        "    return c\n",
        "\n",
        "a = -2.0\n",
        "d = f(a)\n",
        "print(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "LrolvEcc3uBz",
        "outputId": "5d099375-c3ee-4b33-d029-e660646029e9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate values for a\n",
        "a_values = np.linspace(-10, 10, 4000)\n",
        "f_values = np.array([f(a) for a in a_values])\n",
        "grad_values = np.gradient(f_values,a_values)\n",
        "\n",
        "# Plot the function\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(a_values, f_values, label='f(a)', color='blue')\n",
        "plt.axhline(0, color='black', linewidth=0.8)\n",
        "plt.axvline(0, color='black', linewidth=0.8)\n",
        "plt.title('Plot of f(a)')\n",
        "plt.xlabel('a')\n",
        "plt.ylabel('f(a)')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "hbhNHM-d4mYW",
        "outputId": "f2361428-78a2-4dfe-f150-156d41489d6e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(a_values, grad_values, label='grad', color='red')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsqIubTguTFc",
        "outputId": "049a2f7e-231f-4ba2-c238-949a695fcea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(-0.6597, requires_grad=True) tensor(-52.7750, grad_fn=<MulBackward0>)\n",
            "tensor(80.)\n",
            "tensor(True)\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(size=(), requires_grad=True)\n",
        "d = f(a)\n",
        "d.backward()\n",
        "print(a, d)\n",
        "print(a.grad)\n",
        "print(a.grad == d/a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_UKSFbszEmt",
        "outputId": "05eba765-f57b-4a0e-8179-1a6ffebb39b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2.], requires_grad=True) tensor([4.], grad_fn=<MulBackward0>)\n",
            "tensor([2.])\n",
            "tensor([True])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([2.0], requires_grad=True)\n",
        "d = f(a)\n",
        "d.backward()\n",
        "print(a, d)\n",
        "print(a.grad)\n",
        "print(a.grad == d/a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gdc-smmzJYN",
        "outputId": "720a1568-03e8-4692-b6e1-f6d0cd174dd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-0.5000], requires_grad=True) tensor([-40.], grad_fn=<MulBackward0>)\n",
            "tensor([80.])\n",
            "tensor([True])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([-0.5], requires_grad=True)\n",
        "d = f(a)\n",
        "d.backward()\n",
        "print(a, d)\n",
        "print(a.grad)\n",
        "print(a.grad == d/a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCS3qMiq49My"
      },
      "source": [
        "The insight is that, auto-differentiation works for python control flow. You could check the documentation if you are interested."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2CQcRMd0qzK"
      },
      "source": [
        "# More examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q5h8Nvhzxy8",
        "outputId": "6d90b923-1d58-45a0-d7e6-e09e9830f4b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.arange(4.0)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "9OCCr2dU0Aob"
      },
      "outputs": [],
      "source": [
        "x.requires_grad_(True)\n",
        "x.grad  # The default value is None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flciPM5f0baP",
        "outputId": "ec45741c-37c7-4e59-ffa5-04d73a73d6d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(28., grad_fn=<MulBackward0>)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = 2 * torch.dot(x, x)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZ9iFoT-0hHK",
        "outputId": "dc3f2c37-7762-4d93-8326-85ed778a4d83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0.,  4.,  8., 12.])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dbf6jUYS0l7u",
        "outputId": "dcc25738-8065-49b4-8743-6b76e8f6a35f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.grad == 4 * x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ou1c4nH0L73",
        "outputId": "84029005-a4eb-4963-fb11-0baedaec1b22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.grad.zero_()\n",
        "y = x.sum()\n",
        "y.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZtLxjLf050V",
        "outputId": "90b7ade2-4023-4da5-e347-424850854b8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2., 2., 2., 2.])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue2noqWD2Sga"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdHC__qS2CBl",
        "outputId": "f67770ff-d52d-4bf2-e459-1a51a5c7f7d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.grad.zero_()\n",
        "y = x * x\n",
        "u = y.detach() # u has the same value with y, while u is not in any computation graph (thus is a constant)\n",
        "z = u * x\n",
        "\n",
        "z.sum().backward()\n",
        "x.grad == u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3xh0qRS2UZj",
        "outputId": "3ea9c497-ddc8-4314-9e99-fc2044ad03a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0., 1., 4., 9.])\n",
            "tensor([0., 1., 4., 9.], grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(u)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhPc3xs52neF",
        "outputId": "2f4bf2dc-4bcc-4a90-9ced-1d8b2a635ad0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.grad.zero_()\n",
        "y.sum().backward()\n",
        "x.grad == 2 * x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Kwe6xPmKBLrg"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
        "\n",
        "y = x**2\n",
        "# y.requires_grad_(True)\n",
        "y.retain_grad() # for intermediate variables\n",
        "\n",
        "z = sum(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN6bLoE6Bcx4",
        "outputId": "2fe33f96-7f1c-4ef8-97e0-1141d5553829"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2., 3.], requires_grad=True) tensor([4., 9.], grad_fn=<PowBackward0>) tensor(13., grad_fn=<AddBackward0>)\n",
            "None None None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/15/8lcxwsvj7ql4y4cmdw2m1_y00000gn/T/ipykernel_90090/2916361433.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
            "  print(x.grad, y.grad, z.grad)\n"
          ]
        }
      ],
      "source": [
        "print(x,y,z)\n",
        "print(x.grad, y.grad, z.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZl2J1fbBg_X",
        "outputId": "23a79c75-36a1-42a8-ceae-610a68b33010"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([4., 6.]) tensor([1., 1.]) None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/15/8lcxwsvj7ql4y4cmdw2m1_y00000gn/T/ipykernel_90090/2198711337.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
            "  print(x.grad, y.grad, z.grad)\n"
          ]
        }
      ],
      "source": [
        "z.backward()\n",
        "print(x.grad, y.grad, z.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdwpkMTd7PvC"
      },
      "source": [
        "# Reference\n",
        "\n",
        "[AUTOMATIC DIFFERENTIATION WITH TORCH.AUTOGRAD](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env_ST311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
